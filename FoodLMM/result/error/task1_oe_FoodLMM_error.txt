Error at row 490: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 29.61 GiB of which 8.38 MiB is free. Process 5367 has 2.88 GiB memory in use. Including non-PyTorch memory, this process has 15.10 GiB memory in use. Process 2003818 has 11.60 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 172.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error at row 491: CUDA out of memory. Tried to allocate 18.00 MiB. GPU 0 has a total capacity of 29.61 GiB of which 10.38 MiB is free. Process 5367 has 2.88 GiB memory in use. Including non-PyTorch memory, this process has 15.10 GiB memory in use. Process 2003818 has 11.60 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 175.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error at row 615: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 29.61 GiB of which 174.38 MiB is free. Process 5367 has 2.88 GiB memory in use. Including non-PyTorch memory, this process has 15.03 GiB memory in use. Process 2008293 has 11.51 GiB memory in use. Of the allocated memory 14.50 GiB is allocated by PyTorch, and 163.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error at row 616: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 29.61 GiB of which 206.38 MiB is free. Process 5367 has 2.88 GiB memory in use. Including non-PyTorch memory, this process has 15.00 GiB memory in use. Process 2008293 has 11.51 GiB memory in use. Of the allocated memory 14.49 GiB is allocated by PyTorch, and 144.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error at row 856: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 29.61 GiB of which 20.38 MiB is free. Process 5367 has 2.88 GiB memory in use. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Process 2017043 has 11.57 GiB memory in use. Of the allocated memory 14.58 GiB is allocated by PyTorch, and 174.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error at row 482: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 29.61 GiB of which 7.06 MiB is free. Process 5367 has 2.88 GiB memory in use. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Process 2784425 has 8.77 GiB memory in use. Process 2811578 has 2.82 GiB memory in use. Of the allocated memory 14.58 GiB is allocated by PyTorch, and 168.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error at row 1543: CUDA out of memory. Tried to allocate 512.00 MiB. GPU 0 has a total capacity of 29.61 GiB of which 496.38 MiB is free. Process 5367 has 2.88 GiB memory in use. Including non-PyTorch memory, this process has 16.01 GiB memory in use. Process 2971521 has 10.22 GiB memory in use. Of the allocated memory 15.49 GiB is allocated by PyTorch, and 156.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error at row 1442: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 29.61 GiB of which 13.06 MiB is free. Process 5367 has 2.88 GiB memory in use. Including non-PyTorch memory, this process has 15.11 GiB memory in use. Process 3033670 has 8.77 GiB memory in use. Process 3063364 has 2.82 GiB memory in use. Of the allocated memory 14.56 GiB is allocated by PyTorch, and 181.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error at row 1313: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 29.61 GiB of which 12.38 MiB is free. Process 5367 has 2.88 GiB memory in use. Including non-PyTorch memory, this process has 15.13 GiB memory in use. Process 3270106 has 11.57 GiB memory in use. Of the allocated memory 14.58 GiB is allocated by PyTorch, and 180.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error at row 1460: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 29.61 GiB of which 3.06 MiB is free. Process 5367 has 2.88 GiB memory in use. Including non-PyTorch memory, this process has 15.12 GiB memory in use. Process 3275679 has 8.29 GiB memory in use. Process 3282058 has 3.29 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, and 182.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
